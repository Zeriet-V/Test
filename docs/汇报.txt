目前实现了两种基于规则的幻觉检查，分别是基于SVO的幻觉检查和基于N-gram的幻觉检查。

SVO主要是提取主谓宾，然后进行矛盾检测。
N-gram主要是提取词组，通过新颖度，也就是生成文本出现新的词组的比例来判断是否为幻觉，同时引入NER进行二次校验，
当一个句子被N-gram标记为“新颖度过高”时，对句子进行NER分析，查看新的词是否大部分为形容词/副词，还是动词/名词，还是专有名词，还是数词，还是其他词性，

主要在RAGTruth这个数据集上进行测试，发现SVO的效果较差，很多文本都无法提取SVO，而且同义词的情况导致谓语不完全一致。准确率 (Precision): 33.53%，召回率 (Recall): 3.01%，F1分数: 5.53%。

而N-gram的问题主要是检测新词的出现频率，而对于summary，QA这些问题，用同义词的情况很多。而N-gram没有推理能力，所以导致误报的情况很多
准确率 (Precision): 49.45%；召回率 (Recall): 95.59%；F1分数: 65.18%。

下周打算开始基于小模型的实验，想试试BARTScore和Deberta。

问题：
1. 目前基于规则的幻觉检查效果比较差，想问问师兄还有什么推荐的基于规则的方法吗，以及对于下周想进行的实验有什么建议吗。
2. 对于llm-as-judge的方法，GP4的api有什么好用的网站吗，我看我找到的api好像调用费用较贵，因为要输入原文和生成文本，token较多。