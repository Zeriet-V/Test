# BARTScore 幻觉检测方法总结与对比

## 📊 数据集概况

- **总样本数**: 17,790
- **有幻觉样本**: 7,664 (43.08%)
- **无幻觉样本**: 10,126 (56.92%)

**任务分布**:
- Summary: 5,658 样本 (有幻觉29.80%)
- QA: 5,934 样本 (有幻觉29.05%)
- Data2txt: 6,198 样本 (有幻觉68.64%)

---

## 方法一：原版 BARTScore

### 核心思路
使用预训练的 BART 模型计算生成文本相对于原文的对数似然，通过**统一阈值**判断幻觉。

### 技术细节

1. **评分机制**
   ```python
   score = -loss(P(generated_text | source_text))
   ```
   - 分数越低 → 一致性越差 → 可能有幻觉
   - 使用单向评分（仅 source→target）

2. **检测策略**
   - 统一阈值: **-1.8649**
   - 所有任务类型使用相同标准
   - 简单二分类：score < threshold → 幻觉

3. **阈值来源**
   - 基于数据集整体分析确定
   - 可能通过以下方式之一获得：
     * 在验证集上最大化F1分数
     * 基于ROC曲线找最优工作点
     * 基于有/无幻觉样本分数分布的分位数
   - 这个值接近全局平均分数 (-2.16)

3. **实现特点**
   - 模型: `facebook/bart-large-cnn`
   - 批处理大小: 4
   - 评分方式: 前向单向

### 性能表现

**整体指标**:
| 指标 | 数值 |
|------|------|
| 准确率 (Precision) | 53.94% |
| 召回率 (Recall) | 85.87% |
| F1分数 | 66.26 |
| 真阳性 (TP) | 6,581 |
| 假阴性 (FN) | 1,083 |
| 假阳性 (FP) | 5,619 |
| 真阴性 (TN) | 4,507 |

**按任务类型**:
| 任务 | 准确率 | 召回率 | F1 | 评价 |
|------|--------|--------|-----|------|
| Summary | 37.65% | 55.69% | 45.25 | ⚠️ 差 |
| QA | 39.85% | 82.02% | 53.54 | ⚠️ 准确率低 |
| Data2txt | 68.66% | 99.39% | 81.19 | ✅ 较好 |

**按幻觉类型**:
| 幻觉类型 | 检测率 |
|----------|--------|
| Evident Conflict | 91.68% |
| Subtle Conflict | 67.16% |
| Evident Baseless Info | 90.30% |
| Subtle Baseless Info | 91.10% |

### 优缺点分析

**优点** ✅:
- 召回率高（85.87%），漏检少
- 对明显幻觉检测效果好（>90%）
- Data2txt任务表现优秀（99.39%召回率）
- 实现简单，易于部署

**缺点** ❌:
- 准确率较低（53.94%），误报多
- 假阳性过高（5,619个，占83.84%误判）
- 不同任务差异大但使用统一阈值
- Summary任务表现差（准确率仅37.65%）

---

## 方法二：改进版 BARTScore

### 核心改进

针对原版问题，引入三个主要改进：

1. **任务特定阈值** - 为不同任务设置不同检测标准
2. **双向BARTScore** - 同时评估source→target和target→source
3. **置信度评分** - 基于双向分数一致性提供置信度

### 技术细节

1. **双向评分机制**
   ```python
   forward_score = -loss(P(generated | source))
   backward_score = -loss(P(source | generated))
   average_score = (forward + backward) / 2
   confidence = 1 / (1 + |forward - backward|)
   ```

2. **任务特定阈值**
   ```python
   task_thresholds = {
       'Summary':   -1.6500,  # 略宽松
       'QA':        -2.0500,  # 适中
       'Data2txt':  -2.4500   # 严格
   }
   ```

   **阈值设定方法**：
   - 基于各任务类型的**平均BARTScore**设定
   - Summary: 平均 -1.82 → 阈值 -1.65 (放宽约0.17)
   - QA: 平均 -2.12 → 阈值 -2.05 (放宽约0.07)
   - Data2txt: 平均 -2.50 → 阈值 -2.45 (放宽约0.05)
   - **策略**: 比平均值略宽松，希望降低假阳性

3. **检测策略**
   - 根据任务类型动态选择阈值
   - 提供置信度评分（0-1）
   - 支持置信度筛选

### 性能表现

**整体指标**:
| 指标 | 数值 | vs 原版 |
|------|------|---------|
| 准确率 (Precision) | 49.98% | ⬇️ -3.96% |
| 召回率 (Recall) | 64.29% | ⬇️ -21.58% |
| F1分数 | 56.24 | ⬇️ -10.02 |
| 真阳性 (TP) | 4,927 | ⬇️ -1,654 |
| 假阴性 (FN) | 2,737 | ⬆️ +1,654 |
| 假阳性 (FP) | 4,930 | ⬇️ -689 |
| 真阴性 (TN) | 5,196 | ⬆️ +689 |

**按任务类型**:
| 任务 | 准确率 | 召回率 | F1 | vs 原版 |
|------|--------|--------|-----|----------|
| Summary | 36.40% | 72.48% | 48.46 | F1 +3.21 ✓ |
| QA | 41.91% | 70.94% | 52.69 | F1 -0.85 |
| Data2txt | 69.29% | 58.35% | 63.35 | F1 -17.84 ✗✗ |

**按幻觉类型**:
| 幻觉类型 | 检测率 | vs 原版 |
|----------|--------|---------|
| Evident Conflict | 66.90% | ⬇️ -24.78% |
| Subtle Conflict | 54.23% | ⬇️ -12.93% |
| Evident Baseless Info | 68.91% | ⬇️ -21.39% |
| Subtle Baseless Info | 66.13% | ⬇️ -24.97% |

### 优缺点分析

**优点** ✅:
- 假阳性减少689个（误报率降低）
- 真阴性增加689个（准确识别无幻觉样本）
- Summary任务F1提升（45.25→48.46）
- 提供置信度信息，便于人工审核
- 理论上更合理（考虑任务差异和双向一致性）

**缺点** ❌:
- 整体性能下降（F1: 66.26→56.24）
- 召回率大幅下降（85.87%→64.29%）
- 假阴性激增（1,083→2,737，增加153%）
- Data2txt任务崩溃（召回率99.39%→58.35%）
- 所有幻觉类型检测率都下降20%+

---

## 📈 综合对比

### 性能指标对比表

| 维度 | 原版 | 改进版 | 最优 |
|------|------|--------|------|
| **整体F1** | **66.26** | 56.24 | 🏆 原版 |
| **准确率** | 53.94% | 49.98% | 🏆 原版 |
| **召回率** | **85.87%** | 64.29% | 🏆 原版 |
| **假阳性** | 5,619 | **4,930** | 🏆 改进版 |
| **假阴性** | **1,083** | 2,737 | 🏆 原版 |
| Summary F1 | 45.25 | **48.46** | 🏆 改进版 |
| QA F1 | **53.54** | 52.69 | 🏆 原版 |
| Data2txt F1 | **81.19** | 63.35 | 🏆 原版 |

### 适用场景

**推荐使用原版**:
- ✅ 需要高召回率（宁可误报不能漏检）
- ✅ Data2txt 任务为主
- ✅ 对明显幻觉检测要求高
- ✅ 可以接受后续人工复核假阳性

**推荐使用改进版**:
- ✅ 需要降低误报率
- ✅ Summary 任务为主
- ✅ 有置信度需求
- ⚠️ **目前不推荐**（整体性能下降）

---

## 🔍 问题根源分析

### 阈值设定策略对比

#### 原版阈值 (-1.8649)
**可能的设定方法**：
1. **最大化F1分数**
   - 在验证集上搜索最优阈值
   - 找到F1分数最高的切分点
   - 结果：-1.8649

2. **分位数方法**
   - 基于有幻觉样本的分数分布
   - 可能取某个百分位（如75%分位）
   - 确保捕获大部分幻觉

3. **经验调优**
   - 基于1000样本或部分数据集
   - 手动调整到满意效果
   - 权衡准确率和召回率

**特点**：
- ✅ 接近全局平均值 (-2.16)，位置合理
- ✅ 在实验中取得最好的整体效果
- ✅ 简单、易于理解和应用

#### 改进版阈值（任务特定）
**设定方法**：
```
基于各任务平均分数的启发式方法：
threshold = mean_score + offset

Summary:   -1.82 + 0.17 = -1.65
QA:        -2.12 + 0.07 = -2.05
Data2txt:  -2.50 + 0.05 = -2.45
```

**设计思路**：
- 认为不同任务应该有不同标准
- 略微放宽阈值以降低假阳性
- 基于分数分布的经验估计

**问题**：
- ❌ 未在验证集上优化
- ❌ offset值缺乏理论依据
- ❌ 导致Data2txt阈值过严（-2.45太接近平均-2.50）

### 改进版失败的原因

1. **阈值设置失误**
   - Data2txt: -2.45 vs 平均-2.50（间隔仅0.05，太严格！）
     * 有幻觉样本平均约-2.6
     * 无幻觉样本平均约-2.4
     * 阈值-2.45刚好把大量有幻觉样本误判为无幻觉
     * 导致召回率从99%暴跌到58%，漏检1772个
   
   - Summary: -1.65 vs 平均-1.82（放宽0.17，但方向错误）
     * 原本准确率就低（37.65%）
     * 放宽后准确率继续下降到36.40%
     * 召回率提升（55.69%→72.48%）但假阳性更多

2. **双向评分的局限**
   - 增加了计算复杂度（2倍推理时间）
   - 但没有显著提升区分能力
   - 置信度信息利用不足

3. **任务特定阈值的矛盾**
   - 理论合理，但阈值难以准确设定
   - 基于平均分数的经验值不够精确
   - 需要在验证集上优化

### BARTScore方法的固有限制

1. **分数区分度不足**
   - 有幻觉: -2.34 (±0.44)
   - 无幻觉: -2.02 (±0.80)
   - 差异仅0.32，重叠严重

2. **单一指标的局限**
   - 仅考虑文本一致性
   - 未考虑事实性、逻辑性
   - 对Subtle幻觉不敏感

3. **模型依赖性**
   - BART-large-cnn是摘要模型，非专门的幻觉检测模型
   - 可能对某些任务有偏好
   - 需要针对幻觉检测任务微调

---

## 💡 结论与建议

### 最终结论

**原版BARTScore表现更好**:
- F1分数高10分（66.26 vs 56.24）
- 召回率高21%（关键指标）
- 各任务类型表现更均衡
- 实现简单，推理速度快

**改进版未达预期**:
- 整体性能下降
- 假阴性激增（最严重问题）
- 仅假阳性略有改善
- 不推荐直接使用

### 阈值优化的正确方法

如果要继续优化BARTScore，阈值设定应该：

1. **数据驱动的阈值选择**
   ```python
   # 方法1: 网格搜索 + 交叉验证
   for threshold in np.arange(-3.0, -1.0, 0.01):
       precision, recall, f1 = evaluate(threshold)
       # 选择F1最大的阈值
   
   # 方法2: 基于分数分布
   有幻觉分数: mean=-2.34, std=0.44
   无幻觉分数: mean=-2.02, std=0.80
   # 找两个分布的最优分界点
   
   # 方法3: ROC曲线
   # 找假阳性率和真阳性率的最佳平衡点
   ```

2. **任务特定阈值的正确设定**
   - ❌ 错误: `threshold = mean_score + 经验offset`
   - ✅ 正确: 在每个任务的**验证集**上独立优化
   ```python
   for task in ['Summary', 'QA', 'Data2txt']:
       task_data = get_task_data(task)
       optimal_threshold = optimize_f1(task_data)
       task_thresholds[task] = optimal_threshold
   ```

3. **考虑分数分布的重叠度**
   - Data2txt: 有/无幻觉分数差异大 → 可以用较严格阈值
   - Summary: 分数重叠严重 → 阈值调整空间有限
   - 分析每个任务的**可区分性**再设阈值

4. **多阈值策略**
   ```python
   # 不同置信度区间
   if score < -2.5: return "确定有幻觉"
   elif score < -1.8: return "可能有幻觉" 
   elif score < -1.5: return "需人工审核"
   else: return "可能无幻觉"
   ```

### 改进建议

如果要继续优化BARTScore，建议：

1. **优化阈值设定**（核心）
   - ✅ 在验证集上网格搜索最优阈值（必须）
   - ✅ 使用F1分数或业务指标作为优化目标
   - ✅ 对每个任务独立优化（如果用任务特定）
   - ✅ 分析分数分布，确保阈值在合理区间
   - ❌ 不要使用 mean_score + offset 的启发式方法

2. **改进评分机制**
   - 结合其他特征（长度、重叠度、实体一致性）
   - 使用集成方法（多个检测器投票）
   - 考虑句子级检测

3. **模型优化**
   - 使用更大的BART模型（bart-large）
   - 在幻觉检测数据上微调
   - 尝试其他基础模型（T5、ELECTRA等）

4. **超越BARTScore**
   - 考虑专门的幻觉检测模型（如SelfCheckGPT）
   - 使用NLI模型检测矛盾
   - 结合知识库进行事实验证

---

## 📊 最终推荐

**当前最佳方案**: **原版BARTScore**

**配置**:
```python
model_name = 'facebook/bart-large-cnn'
threshold = -1.8649
batch_size = 4
```

**性能**:
- F1分数: 66.26
- 准确率: 53.94%
- 召回率: 85.87%

**适用于**: 幻觉检测初步筛查，可接受较高假阳性率，后续人工审核。

---

## 📁 实验文件

- `bartscore_detector.py` - 原版实现
- `bartscore_detector_improved.py` - 改进版实现
- `bartscore_results_report.txt` - 原版结果
- `bartscore_improved_results_report.txt` - 改进版结果
- `run_comparison.py` - 对比工具

**运行原版**:
```bash
python bartscore_detector.py --gpu 0
```

**运行改进版**:
```bash
python bartscore_detector_improved.py --gpu 0
```

---

## 📌 阈值设定总结

### 原版阈值 -1.8649
- **来源**: 可能通过验证集优化得到（最大化F1）
- **特点**: 接近全局分数分布，经过实验验证
- **效果**: 取得最佳整体性能（F1=66.26）

### 改进版阈值
- **来源**: 基于各任务平均分数 + 经验offset
  ```
  Summary:   mean(-1.82) + 0.17 = -1.65
  QA:        mean(-2.12) + 0.07 = -2.05
  Data2txt:  mean(-2.50) + 0.05 = -2.45
  ```
- **问题**: 
  - ❌ 未在验证集上优化
  - ❌ offset值缺乏依据
  - ❌ 导致Data2txt阈值过严，性能崩溃
- **教训**: 启发式方法不可靠，必须数据驱动

### 关键启示
1. ✅ **阈值必须通过验证集优化**，不能拍脑袋
2. ✅ **任务特定阈值理论上合理**，但执行要正确
3. ✅ **简单方法往往更可靠**（原版统一阈值胜出）
4. ❌ 不要用 `mean + offset` 的经验公式
5. ❌ 不要在测试集上直接调参

---

*报告生成时间: 2025-10-30*
*数据集: test_response_label.jsonl (17,790 samples)*
*阈值设定: 原版基于优化，改进版基于启发式*

