"""
åŸºäºæ£€ç´¢çš„ NLI å¹»è§‰æ£€æµ‹å™¨
Retrieval-Augmented NLI

æ ¸å¿ƒæ€è·¯:
1. ä½¿ç”¨ SentenceTransformer ä»é•¿åŸæ–‡ä¸­æ£€ç´¢æœ€ç›¸å…³çš„è¯æ®
2. ç”¨çŸ­è¯æ® + ç”Ÿæˆæ–‡æœ¬åš NLI
3. é¿å…é•¿æ–‡æœ¬æˆªæ–­ï¼Œä¿ç•™ç›¸å…³ä¿¡æ¯

ä¼˜åŠ¿:
- è§£å†³é•¿æ–‡æœ¬é—®é¢˜
- èšç„¦ç›¸å…³è¯æ®
- é¢„æœŸå‡†ç¡®ç‡å¤§å¹…æå‡
"""

import torch
import json
import os
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np
import re

os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = '300'

print(f"ğŸ”§ é•œåƒè®¾ç½®: {os.environ.get('HF_ENDPOINT')}")


class RetrievalAugmentedNLI:
    """
    åŸºäºæ£€ç´¢çš„ NLI æ£€æµ‹å™¨
    """
    
    def __init__(self,
                 nli_model='MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli',
                 retrieval_model='sentence-transformers/all-MiniLM-L6-v2',
                 device='cuda' if torch.cuda.is_available() else 'cpu',
                 gpu_id=None):
        """
        åˆå§‹åŒ–
        
        :param nli_model: NLI æ¨¡å‹
        :param retrieval_model: æ£€ç´¢æ¨¡å‹ï¼ˆSentenceTransformerï¼‰
        :param device: è®¾å¤‡
        :param gpu_id: GPU ID
        """
        if gpu_id is not None and torch.cuda.is_available():
            device = f'cuda:{gpu_id}'
            torch.cuda.set_device(gpu_id)
            print(f"æŒ‡å®šä½¿ç”¨GPU: {gpu_id}")
        
        self.device = device
        
        print(f"\nåŠ è½½æ¨¡å‹...")
        print(f"  NLIæ¨¡å‹: {nli_model}")
        print(f"  æ£€ç´¢æ¨¡å‹: {retrieval_model}")
        print(f"  è®¾å¤‡: {device}")
        
        # åŠ è½½ NLI æ¨¡å‹
        print("\n1. åŠ è½½ NLI æ¨¡å‹...")
        cache_dir = os.path.expanduser('~/.cache/huggingface/hub')
        nli_cache = os.path.join(cache_dir, f'models--{nli_model.replace("/", "--")}')
        
        try:
            if os.path.exists(nli_cache):
                self.nli_tokenizer = AutoTokenizer.from_pretrained(nli_model, local_files_only=True)
                self.nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model, local_files_only=True)
                print("  âœ“ NLIæ¨¡å‹åŠ è½½æˆåŠŸï¼ˆç¦»çº¿ï¼‰")
            else:
                self.nli_tokenizer = AutoTokenizer.from_pretrained(nli_model)
                self.nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model)
                print("  âœ“ NLIæ¨¡å‹åŠ è½½æˆåŠŸï¼ˆåœ¨çº¿ï¼‰")
        except Exception as e:
            print(f"  âš  ç¦»çº¿åŠ è½½å¤±è´¥ï¼Œå°è¯•åœ¨çº¿...")
            self.nli_tokenizer = AutoTokenizer.from_pretrained(nli_model)
            self.nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model)
            print("  âœ“ NLIæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        self.nli_model.eval()
        self.nli_model.to(self.device)
        
        # åŠ è½½ Sentence Transformer
        print("\n2. åŠ è½½æ£€ç´¢æ¨¡å‹...")
        try:
            from sentence_transformers import SentenceTransformer
            self.retrieval_model = SentenceTransformer(retrieval_model, device=self.device)
            print("  âœ“ æ£€ç´¢æ¨¡å‹åŠ è½½æˆåŠŸ")
        except ImportError:
            print("  âœ— é”™è¯¯: sentence-transformers æœªå®‰è£…")
            print("  è¯·è¿è¡Œ: pip install sentence-transformers")
            raise
        except Exception as e:
            print(f"  âš  ç¦»çº¿åŠ è½½å¤±è´¥: {str(e)[:100]}")
            print("  å°è¯•åœ¨çº¿ä¸‹è½½...")
            self.retrieval_model = SentenceTransformer(retrieval_model, device=self.device)
            print("  âœ“ æ£€ç´¢æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        print("\nâœ“ æ‰€æœ‰æ¨¡å‹åŠ è½½å®Œæˆï¼")
        
        # NLI æ ‡ç­¾æ˜ å°„ï¼ˆå®˜æ–¹æ­£ç¡®æ˜ å°„ - å·²ä¿®å¤ï¼‰
        # 0: entailment, 1: neutral, 2: contradiction
        self.label_mapping = {
            0: 'entailment',     # è•´å«
            1: 'neutral',        # ä¸­ç«‹
            2: 'contradiction'   # çŸ›ç›¾
        }
    
    def split_into_sentences(self, text):
        """
        å°†æ–‡æœ¬åˆ†å¥
        """
        try:
            import spacy
            if not hasattr(self, '_spacy_nlp'):
                try:
                    self._spacy_nlp = spacy.load("en_core_web_sm", disable=["ner", "lemmatizer", "textcat"])
                    if 'sentencizer' not in self._spacy_nlp.pipe_names and 'parser' not in self._spacy_nlp.pipe_names:
                        self._spacy_nlp.add_pipe('sentencizer')
                except:
                    self._spacy_nlp = None
            
            if self._spacy_nlp:
                doc = self._spacy_nlp(text)
                return [sent.text.strip() for sent in doc.sents]
        except:
            pass
        
        # å¤‡ç”¨ï¼šæ­£åˆ™è¡¨è¾¾å¼
        sentences = re.split(r'(?<=[.!?])\s+', text)
        return [s.strip() for s in sentences if s.strip() and len(s) > 10]
    
    def retrieve_relevant_evidence(self, source_text, generated_text, top_k=3, max_evidence_tokens=150):
        """
        ä»åŸæ–‡ä¸­æ£€ç´¢æœ€ç›¸å…³çš„è¯æ®
        
        :param source_text: åŸæ–‡ï¼ˆå¯èƒ½å¾ˆé•¿ï¼‰
        :param generated_text: ç”Ÿæˆæ–‡æœ¬
        :param top_k: æ£€ç´¢top-kä¸ªæœ€ç›¸å…³çš„å¥å­
        :param max_evidence_tokens: è¯æ®æœ€å¤§tokenæ•°
        :return: æ£€ç´¢åˆ°çš„è¯æ®æ–‡æœ¬
        """
        # 1. å°†åŸæ–‡åˆ†å¥
        source_sentences = self.split_into_sentences(source_text)
        
        if not source_sentences:
            # å¦‚æœåˆ†å¥å¤±è´¥ï¼Œç›´æ¥æˆªæ–­
            return source_text[:max_evidence_tokens * 4]  # ç²—ç•¥ä¼°è®¡
        
        if len(source_sentences) <= top_k:
            # å¦‚æœå¥å­æ•°é‡å°‘ï¼Œç›´æ¥è¿”å›å…¨éƒ¨
            return ' '.join(source_sentences)
        
        # 2. è®¡ç®—ç›¸ä¼¼åº¦
        try:
            source_embeddings = self.retrieval_model.encode(source_sentences, convert_to_tensor=True)
            generated_embedding = self.retrieval_model.encode(generated_text, convert_to_tensor=True)
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            from sentence_transformers import util
            similarities = util.cos_sim(generated_embedding, source_embeddings)[0]
            
            # 3. é€‰æ‹©top-kæœ€ç›¸å…³çš„å¥å­
            top_k_indices = torch.topk(similarities, min(top_k, len(source_sentences))).indices
            
            # 4. æŒ‰åŸæ–‡é¡ºåºç»„åˆè¯æ®
            top_sentences = [source_sentences[i] for i in sorted(top_k_indices.cpu().numpy())]
            evidence = ' '.join(top_sentences)
            
            # 5. å¦‚æœè¯æ®å¤ªé•¿ï¼Œå†æˆªæ–­
            words = evidence.split()
            if len(words) > max_evidence_tokens:
                evidence = ' '.join(words[:max_evidence_tokens])
            
            return evidence
            
        except Exception as e:
            print(f"  æ£€ç´¢å¤±è´¥: {str(e)[:50]}, ä½¿ç”¨æˆªæ–­")
            return source_text[:max_evidence_tokens * 4]
    
    def nli_predict(self, premise, hypothesis):
        """
        NLI é¢„æµ‹
        """
        inputs = self.nli_tokenizer(
            premise,
            hypothesis,
            return_tensors='pt',
            truncation=True,
            max_length=512,
            padding=True
        )
        
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = self.nli_model(**inputs)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=-1)[0]
        
        pred_label_id = torch.argmax(probs).item()
        pred_label = self.label_mapping[pred_label_id]
        
        scores = {
            'contradiction': probs[0].item(),
            'neutral': probs[1].item(),
            'entailment': probs[2].item()
        }
        
        return {
            'label': pred_label,
            'scores': scores,
            'contradiction_score': scores['contradiction'],
            'entailment_score': scores['entailment']
        }
    
    def detect_hallucination(self, source_text, generated_text, task_type='Unknown',
                             threshold=0.5, use_entailment=True, 
                             retrieve_evidence=True, top_k=3):
        """
        [!! å…³é”®ä¿®æ­£ !!] - é€å¥æ£€æµ‹
        """
        
        # 1. å°† "ç”Ÿæˆæ–‡æœ¬" æ‹†åˆ†ä¸ºå¥å­
        generated_sentences = self.split_into_sentences(generated_text)
        
        if not generated_sentences:
            # å¦‚æœåˆ†å¥å¤±è´¥ï¼Œå›é€€åˆ°å…¨æ–‡æ£€æµ‹ï¼ˆä½œä¸ºä¿é™©ï¼‰
            return self.nli_predict(source_text, generated_text)

        sentence_results = []
        any_hallucination = False

        for sent in generated_sentences:
            premise = source_text  # é»˜è®¤å‰ææ˜¯åŸæ–‡
            
            # 2. å¯¹ "æ¯ä¸€å¥" è¿›è¡Œæ£€ç´¢ï¼ˆå¦‚æœå¼€å¯ï¼‰
            if retrieve_evidence:
                premise = self.retrieve_relevant_evidence(source_text, sent, top_k=top_k)
            
            # 3. å¯¹ "æ¯ä¸€å¥" è¿›è¡ŒNLIéªŒè¯
            result = self.nli_predict(premise, sent)
            result['evidence_used'] = premise
            result['evidence_retrieved'] = retrieve_evidence

            if use_entailment:
                is_hallucination = result['entailment_score'] < threshold
            else:
                is_hallucination = result['contradiction_score'] > threshold
            
            result['is_hallucination'] = is_hallucination
            sentence_results.append(result)
            
            if is_hallucination:
                any_hallucination = True
        
        # 4. èšåˆç»“æœï¼ˆä½¿ç”¨"æœ€å·®å¥å­"é€»è¾‘ï¼‰
        if not sentence_results: # å†æ¬¡æ£€æŸ¥
            return False, self.nli_predict(source_text, generated_text)
            
        if any_hallucination:
            # æ‰¾æœ€èƒ½è¯æ˜"å¹»è§‰"çš„å¥å­
            if use_entailment:
                worst_result = min(sentence_results, key=lambda x: x['entailment_score'])
            else:
                worst_result = max(sentence_results, key=lambda x: x['contradiction_score'])
        else:
            # æ‰¾æœ€èƒ½è¯æ˜"æ— å¹»è§‰"çš„å¥å­
            if use_entailment:
                worst_result = max(sentence_results, key=lambda x: x['entailment_score'])
            else:
                worst_result = min(sentence_results, key=lambda x: x['contradiction_score'])

        # æ·»åŠ å¥å­çº§è¯¦æƒ…
        worst_result['sentence_level_details'] = {
            'num_sentences': len(generated_sentences),
            'num_hallucination_sentences': sum(1 for r in sentence_results if r['is_hallucination']),
            'all_sentence_results': sentence_results 
        }

        return any_hallucination, worst_result


def quick_test(input_file, output_file, gpu_id=0, sample_size=500, top_k=3):
    """
    å¿«é€Ÿæµ‹è¯•æ£€ç´¢å¢å¼ºçš„æ•ˆæœ
    """
    print("=" * 80)
    print("åŸºäºæ£€ç´¢çš„ NLI æ£€æµ‹å™¨ - å¿«é€Ÿæµ‹è¯•")
    print("=" * 80)
    print(f"æ ·æœ¬æ•°: {sample_size}")
    print(f"Top-K æ£€ç´¢: {top_k}")
    print("=" * 80)
    
    # åˆå§‹åŒ–
    detector = RetrievalAugmentedNLI(gpu_id=gpu_id)
    
    # ç»Ÿè®¡
    total = 0
    tp = fp = fn = tn = 0
    retrieved_count = 0
    
    contradiction_scores_hall = []
    contradiction_scores_no_hall = []
    
    with open(input_file, 'r', encoding='utf-8') as fin, \
         open(output_file, 'w', encoding='utf-8') as fout:
        
        lines = fin.readlines()[:sample_size]
        
        for line in tqdm(lines, desc="æ£€ç´¢å¢å¼ºNLI"):
            total += 1
            data = json.loads(line)
            
            # è§£ææ•°æ®
            test_data = data.get('test', '')
            task_type = data.get('task_type', 'Unknown')
            
            # å¤„ç†ä¸åŒä»»åŠ¡ç±»å‹
            if isinstance(test_data, dict):
                if task_type == 'QA':
                    question = test_data.get('question', '')
                    passages = test_data.get('passages', '')
                    text_original = f"{question} {passages}"
                elif task_type == 'Data2txt':
                    parts = []
                    if 'name' in test_data: parts.append(f"Name: {test_data['name']}")
                    if 'address' in test_data: parts.append(f"Address: {test_data['address']}")
                    if 'city' in test_data and 'state' in test_data: 
                        parts.append(f"Location: {test_data['city']}, {test_data['state']}")
                    if 'categories' in test_data: parts.append(f"Categories: {test_data['categories']}")
                    if 'business_stars' in test_data: parts.append(f"Rating: {test_data['business_stars']} stars")
                    if 'review_info' in test_data and isinstance(test_data['review_info'], list):
                        for i, review in enumerate(test_data['review_info'][:3], 1):
                            if isinstance(review, dict) and 'review_text' in review:
                                parts.append(f"Review {i}: {review['review_text']}")
                    text_original = ' '.join(parts)
                else:
                    text_original = str(test_data)
            else:
                text_original = test_data
            
            text_generated = data.get('response', '')
            has_label = len(data.get('label_types', [])) > 0
            
            if not isinstance(text_original, str): text_original = str(text_original)
            if not isinstance(text_generated, str): text_generated = str(text_generated)
            
            if not text_original.strip() or not text_generated.strip():
                continue
            
            try:
                # æ£€ç´¢å¢å¼º NLI
                detected, result = detector.detect_hallucination(
                    text_original,
                    text_generated,
                    task_type,
                    threshold=0.5,
                    use_entailment=True,      # [!! ä¿®æ­£3 !!] - æ˜ç¡®ä½¿ç”¨è•´å«
                    retrieve_evidence=True,
                    top_k=top_k
                )
                if result['evidence_retrieved']:
                    retrieved_count += 1
                
                # ç»Ÿè®¡
                if has_label and detected: tp += 1
                elif has_label and not detected: fn += 1
                elif not has_label and detected: fp += 1
                else: tn += 1
                
                # è®°å½•åˆ†æ•°
                if has_label:
                    contradiction_scores_hall.append(result['contradiction_score'])
                else:
                    contradiction_scores_no_hall.append(result['contradiction_score'])
                
                # ä¿å­˜ç»“æœ
                fout.write(json.dumps({
                    'id': data.get('id'),
                    'task_type': task_type,
                    'has_label': has_label,
                    'detected': detected,
                    'contradiction_score': result['contradiction_score'],
                    'entailment_score': result['entailment_score'],
                    'nli_label': result['label'],
                    'evidence_retrieved': result['evidence_retrieved'],
                    'evidence': result.get('evidence_used', '')[:200]  # åªä¿å­˜å‰200å­—ç¬¦
                }, ensure_ascii=False) + '\n')
                
            except Exception as e:
                print(f"\né”™è¯¯ (ID: {data.get('id')}): {str(e)[:100]}")
                continue
    
    # è®¡ç®—æŒ‡æ ‡
    precision = tp / (tp + fp) * 100 if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) * 100 if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    
    # åˆ†æ•°åˆ†å¸ƒ
    if contradiction_scores_hall and contradiction_scores_no_hall:
        hall_mean = np.mean(contradiction_scores_hall)
        no_hall_mean = np.mean(contradiction_scores_no_hall)
        separation = abs(hall_mean - no_hall_mean)
    else:
        hall_mean = no_hall_mean = separation = 0
    
    print("\n" + "=" * 80)
    print("ã€æ£€ç´¢å¢å¼º NLI ç»“æœã€‘")
    print("=" * 80)
    print(f"æ ·æœ¬æ•°: {total}")
    print(f"æ£€ç´¢æ ·æœ¬: {retrieved_count} ({retrieved_count/total*100:.1f}%)")
    print(f"\næ€§èƒ½æŒ‡æ ‡:")
    print(f"  å‡†ç¡®ç‡: {precision:.2f}%")
    print(f"  å¬å›ç‡: {recall:.2f}%")
    print(f"  F1åˆ†æ•°: {f1:.2f}")
    print(f"\næ··æ·†çŸ©é˜µ:")
    print(f"  TP: {tp}, FP: {fp}")
    print(f"  FN: {fn}, TN: {tn}")
    print(f"\nåˆ†æ•°åˆ†å¸ƒ:")
    print(f"  æœ‰å¹»è§‰æ ·æœ¬: {hall_mean:.4f}")
    print(f"  æ— å¹»è§‰æ ·æœ¬: {no_hall_mean:.4f}")
    print(f"  åŒºåˆ†åº¦: {separation:.4f}")
    print("=" * 80)
    
    return {
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'separation': separation
    }


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='æ£€ç´¢å¢å¼º NLI æ£€æµ‹å™¨')
    parser.add_argument('--gpu', type=int, default=0, help='GPU ID')
    parser.add_argument('--input', type=str, 
                        default='/home/xgq/Test/data/validation_set.jsonl',
                        help='è¾“å…¥æ–‡ä»¶')
    parser.add_argument('--output', type=str,
                        default='nli_retrieval_test.jsonl',
                        help='è¾“å‡ºæ–‡ä»¶')
    parser.add_argument('--sample-size', type=int, default=500,
                        help='æµ‹è¯•æ ·æœ¬æ•°ï¼ˆé»˜è®¤500ï¼‰')
    parser.add_argument('--top-k', type=int, default=3,
                        help='æ£€ç´¢top-kä¸ªç›¸å…³å¥å­ï¼ˆé»˜è®¤3ï¼‰')
    parser.add_argument('--full-test', action='store_true',
                        help='æµ‹è¯•ä¸åŒçš„top-kå€¼')
    
    args = parser.parse_args()
    
    if args.full_test:
        # æµ‹è¯•ä¸åŒçš„ top-k å€¼
        print("=" * 80)
        print("æµ‹è¯•ä¸åŒçš„ Top-K å€¼")
        print("=" * 80)
        
        results = {}
        for k in [1, 2, 3, 5, 10]:
            print(f"\n\n{'='*80}")
            print(f"æµ‹è¯• Top-K = {k}")
            print("=" * 80)
            
            output = f"nli_retrieval_test_k{k}.jsonl"
            result = quick_test(
                input_file=args.input,
                output_file=output,
                gpu_id=args.gpu,
                sample_size=args.sample_size,
                top_k=k
            )
            results[k] = result
        
        # æ€»ç»“
        print("\n\n" + "=" * 80)
        print("ã€Top-K å¯¹æ¯”æ€»ç»“ã€‘")
        print("=" * 80)
        print(f"{'Top-K':<10} {'å‡†ç¡®ç‡':<12} {'å¬å›ç‡':<12} {'F1':<10} {'åŒºåˆ†åº¦':<10}")
        print("-" * 60)
        for k, r in results.items():
            print(f"{k:<10} {r['precision']:<12.2f} {r['recall']:<12.2f} {r['f1']:<10.2f} {r['separation']:<10.4f}")
        
        best_k = max(results.items(), key=lambda x: x[1]['f1'])[0]
        print(f"\nâœ“ æœ€ä½³ Top-K: {best_k} (F1={results[best_k]['f1']:.2f}%)")
        
    else:
        # å•æ¬¡æµ‹è¯•
        quick_test(
            input_file=args.input,
            output_file=args.output,
            gpu_id=args.gpu,
            sample_size=args.sample_size,
            top_k=args.top_k
        )
        
        print(f"\nä¸‹ä¸€æ­¥:")
        print(f"1. å¦‚æœå‡†ç¡®ç‡æå‡åˆ° 55%+ï¼Œåœ¨å®Œæ•´éªŒè¯é›†ä¸Šè¿è¡Œ")
        print(f"2. ä¼˜åŒ–é˜ˆå€¼")
        print(f"3. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°")

